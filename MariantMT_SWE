import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
import torch

# Configuration 
src_lang = "en"
tgt_lang = "sv"
input_json = "text_data.json"
output_csv = "test_statistics_translated.csv"

# Check for CUDA (GPU) 
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Load Model 
model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
tokenizer = MarianTokenizer.from_pretrained(model_name)
model = MarianMTModel.from_pretrained(model_name).to(device)  # Move model to device (GPU/CPU)

# Translation Function 
def translate(texts, batch_size=8):
    results = []
    for i in range(0, len(texts), batch_size):
        batch = texts[i:i+batch_size]
        inputs = tokenizer(batch.tolist(), return_tensors="pt", padding=True, truncation=True).to(device)  # Move inputs to device (GPU/CPU)
        translated = model.generate(**inputs)
        results.extend([tokenizer.decode(t, skip_special_tokens=True) for t in translated])
    return results

# Load and Translate Data
df = pd.read_json(input_json)

# Translate both columns
df['wikipedia_text_sv'] = translate(df['wikipedia_text'].astype(str))
df['ai_text_sv'] = translate(df['ai_text'].astype(str))

# Save Output
df.to_csv(output_csv, index=False)
print(f"Both columns translated and saved to '{output_csv}'")